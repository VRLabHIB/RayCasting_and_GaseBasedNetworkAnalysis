{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa33faf2-06c3-4096-b20f-c38d7299490b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed3d8b5-0fed-40cb-b6f6-2d4236882ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d134a-6472-4bec-a861-01b11afd6dfb",
   "metadata": {},
   "source": [
    "### Clean dataset and create smaller subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25799f4e-9390-4b71-bdf7-91cbfb39eb5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5666000843048096\n"
     ]
    }
   ],
   "source": [
    "ctime = time.time()\n",
    "df = pd.read_csv(project_path + \"/data/final_A116.csv\", index_col=0, low_memory=False)\n",
    "dfs = df[[\"real_time\", \"object\", \"left.pupil_diameter_mm\", \"right.pupil_diameter_mm\"]]\n",
    "dfs = dfs.loc[(dfs[\"left.pupil_diameter_mm\"]!=-1) & (dfs[\"right.pupil_diameter_mm\"]!=-1)]\n",
    "dfs = dfs.dropna()\n",
    "dfs.columns = ['time', 'gaze_target', 'left.pupil_diameter_mm', 'right.pupil_diameter_mm']\n",
    "dfs.to_csv(project_path + \"/data/smaller_subset_Pyt.csv\", index=False)\n",
    "print(time.time() - ctime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b499e-120d-4673-9930-067035f793d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### I. Aggregating raw gaze-target information into gaze transition datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2842013f-404f-4fe7-ba66-7d14ede02b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.8058979511261\n"
     ]
    }
   ],
   "source": [
    "ctime = time.time()\n",
    "\n",
    "df = pd.read_csv(project_path + \"/data/smaller_subset_Pyt.csv\", low_memory=False)\n",
    "\n",
    "ID = \"001\"\n",
    "\n",
    "ID_lst_new = list()\n",
    "source_lst = list()\n",
    "target_lst = list()\n",
    "time_lst = list()\n",
    "trans_time_lst = list()\n",
    "\n",
    "source = df['gaze_target'].iloc[0]\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    if source != df['gaze_target'].iloc[i]:\n",
    "        ID_lst_new.append(ID)\n",
    "        time_lst.append(df['time'].iloc[i - 1])\n",
    "        trans_time_lst.append(df['time'].iloc[i] - df['time'].iloc[i - 1])\n",
    "        source_lst.append(source)\n",
    "        target_lst.append(df['gaze_target'].iloc[i])\n",
    "\n",
    "        source = df['gaze_target'].iloc[i]\n",
    "\n",
    "df_trans = pd.DataFrame({'participant': ID_lst_new, 'time_point': time_lst, 'trans_dur': trans_time_lst,\n",
    "                         'Source': source_lst, 'Target': target_lst})\n",
    "df_trans.to_csv(project_path + \"/data/transition_Pyt.csv\", index=False)\n",
    "\n",
    "print(time.time() - ctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad529b02-77f3-4ae0-945b-ee0fc7815eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a16f381-5d5f-4a31-a5d1-16d6c5ab79ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011000394821166992\n"
     ]
    }
   ],
   "source": [
    "ctime = time.time()\n",
    "df = pd.read_csv(project_path + \"/data/transition_Pyt.csv\")\n",
    "\n",
    "#Group to weighted adjecency dataframe\n",
    "df_mat = pd.DataFrame(df.groupby(['Source', 'Target'], as_index=False).size())\n",
    "df_mat.columns = ['Source', 'Target', 'Weight']\n",
    "\n",
    "# Normalize\n",
    "#w_sum = np.sum(df_mat['Weight'].values)\n",
    "#df_mat['Weight'] = df_mat['Weight'] / w_sum\n",
    "\n",
    "# Create graph    \n",
    "G = nx.from_pandas_edgelist(df_mat, source='Source', target='Target', edge_attr=['Weight'],\n",
    "                            create_using=nx.MultiDiGraph())\n",
    "print(time.time() - ctime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c1b7f-2199-4e61-9012-13d1bd032296",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54f5cec4-9243-4b62-8bff-9c411c43ee74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009913444519042969\n"
     ]
    }
   ],
   "source": [
    "ctime = time.time()\n",
    "# Weighted degree centrality for specific node\n",
    "node = \"CartoonTeacher\"\n",
    "edges = G.out_edges(node, data=True)\n",
    "sumw = G.out_degree(node, weight='Weight')\n",
    "\n",
    "weight_lst = list()\n",
    "\n",
    "for e in edges:\n",
    "    source, target, weight = e\n",
    "    weight_lst.append(weight['Weight'])\n",
    "\n",
    "# Necessary to compare different graphs with different outgoing nodes.\n",
    "weight_lst.sort()\n",
    "\n",
    "DC = len(edges)\n",
    "FCi = np.zeros(DC - 1)\n",
    "\n",
    "for i in range(DC - 1):  # 0,1,2,3\n",
    "    fj = 0\n",
    "    for j in range(i + 1):\n",
    "        fj += weight_lst[j] / sumw\n",
    "    FCi[i] = fj\n",
    "\n",
    "WDC = 1 + 2 * (np.sum(FCi))\n",
    "print(time.time() - ctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2ebab8b-4eee-41ce-82fa-fca9de77d126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003996849060058594\n"
     ]
    }
   ],
   "source": [
    "# Number of cliques\n",
    "ctime = time.time()\n",
    "stud = ['S11_C', 'S12_C', 'S13_C', 'S14_C', 'S15_C', 'S16_C', \n",
    "          'S17_C', 'S22_C', 'S23_C', 'S24_C', 'S27_C', 'S28_C',\n",
    "          'S32_C', 'S33_C', 'S34_C', 'S35_C', 'S36_C', 'S37_C',\n",
    "          'S38_C', 'S42_C', 'S43_C', 'S44_C', 'S47_C', 'S48_C']\n",
    "\n",
    "SG = nx.induced_subgraph(G,stud) \n",
    "UG = SG.to_undirected()\n",
    "for node in SG:\n",
    "    for ngbr in nx.neighbors(SG, node):\n",
    "        if node in nx.neighbors(SG, ngbr):\n",
    "            UG.edges[node, ngbr, 0]['Weight'] = (SG.edges[node, ngbr, 0]['Weight'] + SG.edges[ngbr, node, 0][\n",
    "                'Weight']) / 2\n",
    "\n",
    "# Find maximal cliques\n",
    "cl = nx.find_cliques(UG)\n",
    "\n",
    "# count number of cliques larger than two nodes with only peers\n",
    "cl_count = 0\n",
    "\n",
    "for c in cl:\n",
    "    if len(c) > 1:\n",
    "        cl_count +=1\n",
    "print(time.time() - ctime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6d635-abcd-4ca9-a237-4e0375d1a077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_venv",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
